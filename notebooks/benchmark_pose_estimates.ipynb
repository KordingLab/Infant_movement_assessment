{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pose estimation model: generate predictions from models in ../model folder\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sys.path.insert(0,'../src/pose_model')\n",
    "import get_pose_model_predictions_and_groundtruth\n",
    "\n",
    "check_gpu_is_running =1\n",
    "if check_gpu_is_running==1:\n",
    "    print('CHECK GPU (look for output that mentions GPU)')\n",
    "    print(K.tensorflow_backend._get_available_gpus())\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(device_lib.list_local_devices())\n",
    "    # Creates a graph.\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    # Creates a session with log_device_placement set to True.\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(c))\n",
    "\n",
    "get_pose_model_predictions_and_groundtruth.main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
